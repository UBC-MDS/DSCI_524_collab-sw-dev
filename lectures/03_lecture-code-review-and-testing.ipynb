{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSCI 524 - Collaborative Software Development\n",
    "\n",
    "### Lecture 3: Code reviews, functional testing and advice for testing complex things\n",
    "\n",
    "#### 2020-03-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3 learning objectives:\n",
    "By the end of this lecture, students should be able to:\n",
    "\n",
    "- [Perform a code review that uses inline comments and suggested code fixes.](#Code-reviews-using-in-line-comments-and-suggested-code-fixes)\n",
    "- Define the following 3 types of testing:\n",
    "    - unit testing\n",
    "    - integration testing\n",
    "    - regression testing\n",
    "- Employ a workflow that optimizes accurate code.\n",
    "- Use `pytest` and `testhat` to run a project's entire test suite\n",
    "- Explain how `pytest` and `testhat` find the test functions when they are asked to run a project's entire test suite\n",
    "- [Write unit tests for complex objects (e.g., data frames, models, plots).](#Write-unit-tests-for-complex-objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code reviews using in-line comments and suggested code fixes\n",
    "\n",
    "<img src =\"https://help.github.com/assets/images/help/commits/hover-comment-icon.gif\" width=800>\n",
    "\n",
    "*Source: <https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/reviewing-proposed-changes-in-a-pull-request>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: do a code review:\n",
    "\n",
    "We are going to each do our own code review of a pull request. I have set-up a template GitHub repository for you so that you can easily generate a pull request for you to review.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "**When you are done step #5 indicate so on the [sli.do](https://www.sli.do) poll (`#524-L03`).**\n",
    "\n",
    "1. **Import** [this repository](https://github.com/ttimbers/review-my-pull-request) to obtain a copy of it for yourself (do not fork it).\n",
    "\n",
    "2. Create a remote branch named `pr` (this will use GitHub Actions to create a pull request for you to review in this repository).\n",
    "\n",
    "3. Click on the Pull Requests tab of your copy of the repository, click on the pull request titled \"Report most accomplished pilots\", and then click on \"Files Changed\". Next click on the `star-wars.Rmd` file. Review the file and observe the following problems with the R Markdown report that was submitted via the pull request:\n",
    "  - Reasoning of the sentence on line 15\n",
    "  - Incompatibility with the sentence on line 15 with the code in the code chunk named `table-of-most-accomplished-pilots`\n",
    "  - Incorrect code in code chunk named `table-of-most-accomplished-pilots` (unested `film` instead of `starships`) leads to naming the wrong pilot as the most accomplished pilot on line 27\n",
    "  - Incorrect code in code chunk named `table-of-most-accomplished-pilots` (unested `film` instead of `starships`) leads to the use of the wrong character's picture in the image that is sourced in the code chunk named `top-pilot` (it should be a picture of Han Solo, you could use this URL for example: <https://i1.wp.com/twinfinite.net/wp-content/uploads/2015/11/harrison-ford-Mill_3222044i.jpg>).\n",
    "\n",
    "4. Add comments and suggested changes using the `+` sign beside the line numbers (the first time you do this will trigger the start of your code review. Need help? See [GitHub's how to on reviewing proposed changes in a pull request](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/reviewing-proposed-changes-in-a-pull-request).\n",
    "\n",
    "5. After you have made all the comments and suggested changes, then add a general comment for the code review, select \"Request Changes\" and submit your code review.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you are done step #5 indicate so on the [sli.do](https://www.sli.do) poll (`#524-L03`).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Accept suggested changes from a code review:\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Practice accepting code changes that you provided as suggestions by revisiting the Pull Requests tab of your copy of the repository and clicking on the pull request titled \"Report most accomplished pilots\". Scroll through the pull request comments and find the code suggestions. Then click on the \"Commit suggestion button\" for each suggestion. \n",
    "\n",
    "2. Click on the \"Show all reviewers\" link beside the red \"Changes requested\"\" text. Then click on the `...` beside the reviewer and click \"Approve changes\".\n",
    "\n",
    "3. Finally click on the green buttons (\"Merge Pull Request\" & \"Confirm merge\") to merge the pull request.\n",
    "\n",
    "**When you are done step #3 indicate so on the [sli.do](https://www.sli.do) poll (`#524-L03`).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: \n",
    "\n",
    "Was there anything we should have done differently with that code review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: if I didn't tell you that the top pilot was Han Solo, how would you have known that?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some common types of testing\n",
    "\n",
    "- unit testing\n",
    "- integration testing\n",
    "- regression testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write unit tests for complex objects \n",
    "(e.g., data frames, models, plots)\n",
    "\n",
    "Writing unit tests for a single value, vector or list is fairly straight forward from what we have learned in 511, but what about more complex object? How do we write tests when our functions return:\n",
    "\n",
    "- data frames?\n",
    "- plot objects?\n",
    "- model objects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General guidelings for testing data frames\n",
    "\n",
    "- Where possible, use functions designed specifically for this (e.g., `dplyr::all_equal` and `pandas.DataFrame.equals`).\n",
    "- If not possible, test for equality of important values (e.g., specific columns) and attributes (e.g., shape, column names, column type, etc) using the `expect_*` functions inside of `test_that` in R, or via assertions in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: example of tests for a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General guidelings for testing plot objects\n",
    "\n",
    "- Initial tests should be designed to test that plots have expected attributes (e.g., expected mark, correct mapping to axes, etc)\n",
    "- Once a desired plot is generated, visual regression tests can be used to ensure that further code refactoring does not change the plot function. Tools for this exist for R in the [`vdiffr`](https://github.com/r-lib/vdiffr) package. AFAIK the Python tools in this space have only been developed/used for GUI & web apps, perhpas they could be used for plots as well? I have not yet tried (nor found any examples of anyone who has)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: example of tests for a plot object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General guidelings for testing model objects\n",
    "\n",
    "- Initial tests should be designed to test that models have expected attributes and results\n",
    "- Only secondarily, may you want to compare to existing methods (rationale for this being second: what if their tests are wrong? Or worse, what if they don't have any!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: example of tests for a model object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But I have another type of object? How do I test it?\n",
    "\n",
    "If you don't know where to start writing tests for the object you plan to use or return in your function, try the following:\n",
    "- make such an object and interactively explore it\n",
    "- look at other packages that have functions and return the same kind of object, what do they test for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How testthat works:\n",
    "\n",
    "To run all tests in an R package that uses `testthat`, run the following from the R console with the working directory being set as the package's root directory:\n",
    "\n",
    "```\n",
    "devtools::test()\n",
    "```\n",
    "\n",
    "This command is a shortcut for `testthat::test_dir()`, and it runs all the files that live in `tests/testthat/` that start with `test`.\n",
    "\n",
    "*Source: [R Packages, Chapter 10](https://r-pkgs.org/tests.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing tests for your R package:\n",
    "\n",
    "Tests are organised hierarchically: **expectations** are grouped into **tests** which are organised in **files**:\n",
    "\n",
    "- An **expectation** is the atom of testing. It describes the expected result of a computation: Does it have the right value and right class? Does it produce error messages when it should? An expectation automates visual checking of results in the console. Expectations are functions that start with `expect_`.\n",
    "\n",
    "- A **test** groups together multiple expectations to test the output from a simple function, a range of possibilities for a single parameter from a more complicated function, or tightly related functionality from across multiple functions. This is why they are sometimes called **unit** as they test one unit of functionality. A test is created with `test_that()`.\n",
    "\n",
    "- A **file** groups together multiple related tests. Files are given a human readable name with `context()`.\n",
    "\n",
    "*Source: [R Packages, Chapter 10](https://r-pkgs.org/tests.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How pytest works:\n",
    "\n",
    "To run all tests in an Python package that uses `pytest`, run the following from the command line with the working directory being set as the package's root directory:\n",
    "\n",
    "```\n",
    "poetry run pytest\n",
    "```\n",
    "\n",
    "> Note: because we are using Poetry to build our packages, we need to prefix the pytest command with `poetry run` so that the tests are run in our package's virtual environment.\n",
    "\n",
    "This command runs a recursive search (downward from the directory where this command is run) for files that are prefixed with `test_*.py` or `*_test.py` files which are imported by their test package name. From these files, it will run the functions whose names are pre-fixed with `test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General guidelines for test data and helper functions:\n",
    "\n",
    "- Keep your tests fast by creating toy data or using built-in data (e.g, `mtcars`) that you can feed to your unit tests. If you create toy data, do this within the unit test code block/function that uses that data. \n",
    "- If your tests need to be DRY'ed out in R, then:\n",
    "    - put your helper functions in a file in the `tests/testthat` directory that and pre-fix the filename with `helper` so that they will be run before the tests.\n",
    "    - store your data as a file in the `tests` directory.\n",
    "- If your tests need to be DRY'ed out in Python, then:\n",
    "    - put your helper functions in a file in the `tests` directory that uses `helper` in the filename to distinguish them from your user-facing functions. Do not use `test` in the name for these functions.\n",
    "    - either store your data as a file in the `tests` directory or use [pytest fixtures](https://www.tutorialspoint.com/pytest/pytest_fixtures.htm) to generate data in a function before the tests are run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
